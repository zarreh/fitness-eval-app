# ── Fitness Evaluation App — Docker Compose (Production) ───────────────────────
#
# Uses OpenAI as the LLM provider. Set credentials in backend/.env:
#   LLM_PROVIDER=openai
#   LLM_MODEL=gpt-4o
#   OPENAI_API_KEY=sk-...
#
# Quick start:
#   1. cp .env.example backend/.env   # create the env file and fill in OpenAI key
#   2. docker compose up --build      # build images and start services
#
# For local development with Ollama (no OpenAI key needed):
#   docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build
#   (or: make docker-dev-up)
#
# Services:
#   backend  → http://localhost:8000   (FastAPI + WeasyPrint)
#   frontend → http://localhost:8501   (Streamlit)

services:

  # ── FastAPI backend ───────────────────────────────────────────────────────────
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      # Load LLM_PROVIDER, LLM_MODEL, OPENAI_API_KEY, etc. from backend/.env.
      # The file is optional — Dockerfile ENV defaults apply when it is absent.
      - path: backend/.env
        required: false
    volumes:
      # Persist clients.json across container rebuilds.
      - backend_data:/app/data
    healthcheck:
      test:
        - "CMD"
        - "python"
        - "-c"
        - "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  # ── Streamlit frontend ────────────────────────────────────────────────────────
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    environment:
      # Point the frontend at the backend service by its internal hostname.
      API_URL: "http://backend:8000"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test:
        - "CMD"
        - "python"
        - "-c"
        - "import urllib.request; urllib.request.urlopen('http://localhost:8501/_stcore/health')"
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 20s
    restart: unless-stopped

volumes:
  # Persists clients.json (saved client history) across container rebuilds.
  backend_data:
